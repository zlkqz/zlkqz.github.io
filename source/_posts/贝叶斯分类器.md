---
title: 贝叶斯分类器
math: true
date: 2022-4-26
---



# 1 贝叶斯决策论

- 假设有N个可能的类别$$\mathcal{Y} = \{c_1, ..., c_N\}$$，$\lambda_{ij}$是将一个$c_i$类样本误分类为$c_j$类的损失，则在样本x上的条件风险为：

$$
R\left(c_{i} \mid \boldsymbol{x}\right)=\sum_{j=1}^{N} \lambda_{i j} P\left(c_{j} \mid \boldsymbol{x}\right)
$$

- 我们的任务是寻找一个判定准则$$h: \mathcal{X} \mapsto \mathcal{Y}$$以最小化总体风险：

$$
R(h)=\mathbb{E}_{\boldsymbol{x}}[R(h(\boldsymbol{x}) \mid \boldsymbol{x})]
$$



- 显然，对每个样本x，若能最小化条件风险$$R(h(x) | x)$$，则总体风险$R(h)$也被最小化。这就产生了**贝叶斯判定准则（Bayes decision rule）**：为最小化总体风险，只需在每个样本上选择那个能使条件风险最小的类别标记，即：

$$
h^{*}(\boldsymbol{x})=\underset{c \in \mathcal{Y}}{\arg \min } R(c \mid \boldsymbol{x})
$$

**此时，$h^*$称为贝叶斯最优分类器**

- 具体来说，若目标是最小化分类错误率，则误判损失可以写为0/1损失：

$$
\lambda_{ij}  = \begin{cases}
0, if \quad i = j \\
1, otherwise
\end {cases}
$$

- 则此时条件风险为：

$$
R(c|x) = 1 - P(c|x)
$$

- 所以贝叶斯最优分类器为：

$$
h^*(x) = arg\ max_{c \in \mathcal{Y}}P(c|x)
$$

**即对每个样本x，选择能使后验概率$P(c|x)$最大的类别标记**

- 所以首先要获得后验概率，然而这在现实任务中难以直接获得，所以机器学习的任务是**基于有限的训练样本集尽可能准确地估计出后验概率**，大体有两种策略：

> - **判别式模型（discriminative models）：**直接建模后验概率$P(c|x)$来预测c，决策树、SVM、神经网络等都是判别式模型
> - **生成式模型（generative models）：**先对联合概率分布$P(x, c)$建模，再由此得到后验概率$P(c|x)$

- 对于生成式模型，必然考虑贝叶斯定理：

$$
P(c|x) = \frac{P(x, c)}{P(x)} \\ = \frac{P(c)P(x|c)}{P(x)}
$$

其中，$P(c)$是先验概率，$P(x|c)$是似然，$P(x)$是用于归一化的证据因子，与类标记无关，所以建模的时候都是把分母$P(x)$直接去掉。所以现在，**估计后验概率$P(c|x)$的任务就会转化为如何基于训练集D来估计先验概率$P(c)$和似然$P(x|c)$ **。在训练集足够大的时候可以直接用样本频率代替$P(c)$。而$P(x|c)$显然是无法通过频率估计的（不同属性的组合结果太多）

> 基于有限训练样本直接估计联合概率，在计算上将会遭遇组合爆炸问题，在数据上将会遭遇样本稀疏问题。属性数越多，问题越严重





# 2 极大似然估计

- 求解$P(x|c)$的一个方法就是使用极大似然估计（MLE），这需要先假定其**具有一种确定的概率分布形式**，再基于训练样本对概率分布的参数进行估计

- 具体来说，记关于类别c的似然为$P(x|c)$，假设$P(x|c)$具有确定的形式并且被参数向量$\theta_c$唯一确定，我们的任务就是通过训练集估计参数$\theta_c$，为明确起见，将$P(x|c)$记为$P(x|\theta_c)$。令$D_c$为数据集D中第c类样本的集合，假设这些样本独立同分布，则参数$\theta_c$关于$D_c$的似然是：

$$
P(D_c|\theta_c) = \prod_{x \in D_c}P(x|\theta_c)
$$

- 然后再对上式取负对数得到$LL(\theta_c)$，最后得到极大估计值$$\hat{\theta_c}$$：

$$
\hat{\boldsymbol{\theta}}_{c}=\underset{\boldsymbol{\theta}_{c}}{\arg \max } L L\left(\boldsymbol{\theta}_{c}\right)
$$





# 3 朴素贝叶斯分类器

### 3.1 基本概念

- 上面已经说过最大的困难在于$P(x|c)$难以从有限的样本中估计而得。而朴素贝叶斯采用了**属性条件独立性假设：对已知类别，假设所有属性相互独立**

- 则生成式模型的目标可以重写为：

$$
P(c \mid \boldsymbol{x})=\frac{P(c) P(\boldsymbol{x} \mid c)}{P(\boldsymbol{x})}=\frac{P(c)}{P(\boldsymbol{x})} \prod_{i=1}^{d} P\left(x_{i} \mid c\right)
$$

其中d为属性个数，$x_i$为样本$x$在第$i$个属性上的取值

- 所以朴素贝叶斯分类器的表达式为：

$$
h_{n b}(\boldsymbol{x})=\underset{c \in \mathcal{Y}}{\arg \max } P(c) \prod_{i=1}^{d} P\left(x_{i} \mid c\right)
$$

- 上式的概率都可以通过统计频率获得：

$$
P(c) = \frac{|D_c|}{|D|} \\ P(x_i|c) = \frac{|D_{c, x_i}|}{|D_c|}
$$

其中$$D_c$$为类别为c的样本集，$$D_{c, x_i}$$为类别为c并在第$$i$$个属性上取值$$x_i$$的样本集。若是对于连续属性可考虑概率密度函数，比如$$p\left(x_{i} \mid c\right) \sim \mathcal{N}\left(\mu_{c, i}, \sigma_{c, i}^{2}\right)$$，$$\mu_{c, i}$$和$$\sigma^2_{c, i}$$分别是第c类样本在第$$i$$个属性上取值的均值和方差



### 3.2 引入先验分布

- 在上面计算概率时，若某个属性值在训练集中没有与某个类同时出现过，则会导致0乘，频率估计将会出现问题。所以要进行平滑处理，常用**拉普拉斯修正（Laplacian correction）**
- 具体来说，令N表示可能的类别数，$N_i$表示第$i$个属性可能的取值数，则上面的概率计算式可以修正为：

$$
\begin{aligned}
\hat{P}(c) &=\frac{\left|D_{c}\right|+1}{|D|+N} \\
\hat{P}\left(x_{i} \mid c\right) &=\frac{\left|D_{c, x_{i}}\right|+1}{\left|D_{c}\right|+N_{i}}
\end{aligned}
$$

- 显然，拉普拉斯是**引入了一个均匀分布的先验分布**，避免了上述的0乘问题，并且在训练集变大时，修正过程索隐入的先验分布的影响也会逐渐变得可忽略，使得估值逐渐趋于实际概率值





# 4 半朴素贝叶斯分类器

- 朴素贝叶斯是采用了属性条件独立性假设，但是在现实任务中往往很难成立，于是尝试对这种假设进行一定的放松，由此产生了半朴素贝叶斯分类器。**基本思想是适当考虑一部分属性间的相互依赖信息，从而既不需进行完全联合概率计算，又不至于彻底忽略了比较强的属性依赖关系**
- **独依赖估计（One-Dependent Estimator, OED）**是半朴素贝叶斯分类器最常用的一种策略，就是**假设每个属性在类别之外最多仅依赖一个其他属性**，即：

$$
P(c \mid \boldsymbol{x}) \propto P(c) \prod_{i=1}^{d} P\left(x_{i} \mid c, p a_{i}\right)
$$

其中$pa_i$为$x_i$的父属性，若$pa_i$已知，则可以通过前面的方法计算$$P(x_i|c, pa_i)$$，所以问题就转化为如何确定每个属性的父属性



### 4.1 SPODE

- SPODE（Super-Parent ODE）方法是**假设所有属性都依赖于同一个属性，成为超父，然后通过交叉验证等模型选择方法来确定超父属性**



### 4.2 TAN

- TAN（Tree Augmented naive Bayes）是在最大带权生成树的基础上构建的依赖关系，具体步骤如下：

> 1. 计算任意两个属性之间的条件互信息（conditional mutual information）：
>
> $$
> I\left(x_{i}, x_{j} \mid y\right)=\sum_{x_{i}, x_{j} ; c \in \mathcal{Y}} P\left(x_{i}, x_{j} \mid c\right) \log \frac{P\left(x_{i}, x_{j} \mid c\right)}{P\left(x_{i} \mid c\right) P\left(x_{j} \mid c\right)}
> $$
>
> 2. 以属性作为结点构建完全图，每两个节点之间边的权重为$$I(x_i, x_j|y)$$
> 3. 构建此完全图的最大带权生成树，挑选根节点，并将边置为有向
> 4. 加入类别结点y，增加y到每个属性的有向边

- 以下是朴素贝叶斯（NB）和两种ODE的对比：

<img src="https://zlkqzimg-1310374208.cos.ap-chengdu.myqcloud.com/image-20220926174528428.png" alt="image-20220926174528428" style="zoom:80%;" />



### 4.3 AODE

- AODE（Averaged One-Dependent Estimator）是一种基于集成学习的ODE，与SPODE通过模型选择确定超父属性不同，**AODE尝试将每个属性作为超父来构建SPODE，然后将那些具有足够训练数据支撑的SPODE集成起来作为最终结果**，即：

$$
P(c \mid \boldsymbol{x}) \propto \sum_{\substack{i=1 \\\left|D_{x_{i}}\right| \geqslant m^{\prime}}}^{d} P\left(c, x_{i}\right) \prod_{j=1}^{d} P\left(x_{j} \mid c, x_{i}\right)
$$

其中$$D_{x_i}$$是在第$i$个属性上取值为$x_i$的样本集合，$m^{\prime}$为阈值（默认为30）

- 概率统计公式如下：

$$
\begin{aligned}
\hat{P}\left(c, x_{i}\right) &=\frac{\left|D_{c, x_{i}}\right|+1}{|D|+ N \times N_{i}} \\
\hat{P}\left(x_{j} \mid c, x_{i}\right) &=\frac{\left|D_{c, x_{i}, x_{j}}\right|+1}{\left|D_{c, x_{i}}\right|+N_{j}}
\end{aligned}
$$

- 注意：SPODE是假设类别和超父属性相互独立，所以连乘项前面是乘$P(c)$；而AODE则没有假设两者独立，所以连乘项前是乘$P(c|x_i)$





# 5 贝叶斯网

- 贝叶斯网亦称信念网，借助有向无环图（DAG）来刻画属性之间的依赖关系，并使用条件概率表（CPT）来描述属性间的联合概率分布

- 具体来说，一个贝叶斯网B由结构G和参数$$\Theta$$构成，即$$B = <G, \Theta>$$。G是一个有向无环图，每个节点对应一个属性，若两个属性有直接依赖关系，则由一条边连接起来。$$\Theta$$定量描述这种依赖关系，假设属性$$x_i$$的父节点集为$$\pi_i$$，则$$\Theta$$包含了每个属性的条件概率表$$\theta_{x_i|\pi_i} = P_B(x_i|\pi_i)$$。如下图：

<img src="https://zlkqzimg-1310374208.cos.ap-chengdu.myqcloud.com/image-20220927112128167.png" alt="image-20220927112128167"  />



### 5.1 结构

- 贝叶斯网有效的表达了属性间的条件独立性，**给定父节点集，贝叶斯网假设每个属性与他的非后裔属性独立**，那么属性$$x_1, ...,x_d$$的联合概率分布为：

$$
P_{B}\left(x_{1}, x_{2}, \ldots, x_{d}\right)=\prod_{i=1}^{d} P_{B}\left(x_{i} \mid \pi_{i}\right)=\prod_{i=1}^{d} \theta_{x_{i} \mid \pi_{i}}
$$

- 贝叶斯网中有3种典型的依赖关系：



![image-20220927161634626](https://zlkqzimg-1310374208.cos.ap-chengdu.myqcloud.com/image-20220927161634626.png)

1、同父结构中，给定父节点$x_1$的值，则$x_3$和$x_4$条件独立

> **证明：**
>
> $$
> P(x_1, x_3, x_4) = P(x_1)P(x_3|x_1)P(x_4|x_1) \\
> P(x_3, x_4| x_1) = P(x_1, x_3, x_4) / P(x_1)
> $$
> 联立上述两式：
> $$
> P(x_3, x_4| x_1) = P(x_3|x_1)P(x_4|x_1)
> $$

2、顺序结构中，给定x的值，则y和z条件独立

> **证明：**
> $$
> P(x, y, z) = P(z)P(x|z)P(y|x) = P(x)P(z|x)P(y|x) \\
> P(z, y | x) = P(x, y, z) / P(x)
> $$
> 联立上述两式：
> $$
> P(z, y | x) = P(z|x)P(y|x)
> $$

3、V型结构中，给定$x_4$的取值，则$x_1$和$x_2$必不独立；但是若$x_4$取值完全未知，则$x_1$和$x_2$却是相互独立的（**边际独立性**）

> **证明：**
>
> $$
> P(x_1, x_2) = \sum_{x_4}P(x_1, x_2, x_4) = \sum_{x_4}P(x_1)P(x_2)P(x_4|x_1, x_2) = P(x_1)P(x_2)
> $$



### 5.2 有向分离

- 可以使用**有向分离（D-separation）**分析有向图中变量间的条件独立性
- 首先要把有向图转化为无向图，由此产生的无向图称为道德图：

> 1. 找出有向图中的所有V型结构，在V型结构的两个父节点之间加上一条无向边
> 2. 然后将所有有向边改为无向边

- 基于道德图能直观迅速地找到变量间地条件独立性。假定道德图中有变量$x,y$和变量集合$$z = \{z_i\}$$。若变量x和y能在图上被z分开，即从道德图中将变量集合z去除后，x和y分属两个连通分支，则称x和y被有向分离，$$x \perp y | z$$成立



### 5.3 学习

- 贝叶斯网学习的首要任务是根据训练数据来找出结构最恰当的贝叶斯网。**评分搜索**是求解的常用方法，具体来说，先定义一个评分函数，以此来评估贝叶斯网与训练数据的契合程度，然后基于这个评分函数来寻找结构最优的贝叶斯网

- 常用评分函数通常基于信息论准则，此类准则将学习问题看作一个数据压缩任务，学习的目标是找到一个能以最短编码长度描述训练数据的模型，此时**编码的长度包括了描述模型自身所需的字节长度和使用该模型描述数据所需的字节长度**。对贝叶斯网学习而言,模型就是一个贝叶斯网
- 每个贝叶斯网描述了一个在训练数据上的概率分布，**自有一套编码机制能使那些经常出现的样本有更短的编码**。于是应**选择那个综合编码长度(包括描述网络和编码数据)最短的贝叶斯网**，这就是**最小描述长度(Minimal Description Length,MDL)准则**
- 若给定训练集$$D = \{x_1, ..., x_m\}$$（每个样本向量中是包含了类别的），则贝叶斯网$$B = <G, \Theta>$$在D上的评分函数可以写为：

$$
s(B \mid D)=f(\theta)|B|-L L(B \mid D)
$$

其中|B|是贝叶斯网络的参数个数，$f(\theta)$表示描述每个参数$\theta$所需的编码位数；而第二项$$L L(B \mid D)=\sum_{i=1}^{m} \log P_{B}\left(x_{i}\right)$$是贝叶斯网B的对数似然。**显然第一项是计算编码贝叶斯网B所需的编码位数，第二项是计算B所对应的概率分布$P_B$对D描述的有多好**

> - 若$f(\theta)=1$，则得到AIC评分函数：
>
> $$
> \operatorname{AIC}(B \mid D)=|B|-L L(B \mid D)
> $$
>
> - 若$f(\theta) = \frac{1}{2}\log m$，则得到BIC评分函数：
>
> $$
> \operatorname{BIC}(B \mid D)=\frac{\log m}{2}|B|-L L(B \mid D)
> $$

- 若贝叶斯网B的网络结构G固定，则评分函数第一项为常数，那么最小化$s(B|D)$等价于对参数$\Theta$的极大似然估计，而此时每个参数$$\theta_{x_i|\pi_i}$$可以直接从D中通过频率统计获得。**所以，要最小化评分函数，只需对网络每种结构进行搜索，而候选结构的最优参数可直接在训练数据D上计算得到**

> 但是搜索所有可能的结构是一个NP难问题。但是可以采用一些策略求得近似解，比如：
>
> 1. 贪心法，从某个网络结构出发，每次调整一条边（增加、删除、调整方向），直到评分函数不再降低
> 2. 添加约束，比如将网络结构限定为树形结构（比如TAN）



### 5.4 推断

- 贝叶斯网训练好之后就能用来回答“查询”（query），即通过一些属性变量的观测值来推测其他属性变量的取值（类别也算作一个变量）。例如在西瓜问题中，若我们观测到西瓜色泽青绿、敲声浊响、根蒂蜷缩，想知道它是否成熟、甜度如何。**这样通过已知变量观测值来推测待查询变量的过程称为“推断”（inference），已知变量观测值称为“证据”（evidence）**

- 理想情况下是直接通过贝叶斯网定义的联合概率分布来计算后验概率，但是在节点多、连接稠密时，难以进行这样的精确推断，这时需借助**近似推断**，尝试用**吉布斯采样（Gibbs sampling）**

- 具体来说，$$Q = \{Q_1, ..., Q_n\}$$表示带查询变量，$$E = \{E_1, ..., E_k\}$$表示证据变量，其取值为$$e = \{e_1, ..., e_k\}$$。我们的任务是计算后验概率$$P(Q=q|E=e)$$，其中$$q = \{q_1, ..., q_n\}$$代表查询变量的一组取值

- 吉布斯采样步骤如下：

<img src="https://zlkqzimg-1310374208.cos.ap-chengdu.myqcloud.com/image-20220927213559671.png" alt="image-20220927213559671" style="zoom:80%;" />

> 一开始先产生一个与证据$E = e$一致的样本$q^0$作为初始点，然后经过T次迭代，每次迭代都对非证据变量（即Z）逐个采样，然后由贝叶斯的概率分布推断其取值。若经过T次采样得到的与q一致的样本共有$n_q$个，则可近似估算出后验概率：
> $$
> P(\mathbf{Q}=\mathbf{q} \mid \mathbf{E}=\mathbf{e}) \simeq \frac{n_{q}}{T}
> $$





# 6 EM算法

- 上面的讨论中，都是认定训练样本是完整的，但是现实应用中往往有的属性值未知，这些未观测变量称为**隐变量（latent variable）**，在这种存在隐变量的情况下进行参数估计，可使用EM算法



### 6.1 基本思想

- EM 算法的核心思想非常简单，分为两步：Expectation-Step 和 Maximization-Step。E-Step 主要通过观察数据和现有模型来估计参数，然后用这个估计的参数值来计算似然函数的期望值；而 M-Step 是寻找似然函数最大化时对应的参数。由于算法会保证在每次迭代之后似然函数都会增加，所以函数最终会收敛
- 于是以随机初始值$\Theta^0$为起点，执行以下步骤直至收敛：

> 1. 基于$\Theta^t$推断隐变量Z的期望，记为$Z^t$
> 2. 基于已观测变量X和$Z^t$对参数$\Theta$做最大似然估计，记为$$\Theta^{t+1}$$



### 6.2 举个栗子

- 有两枚硬币A、B，随机抛掷结果如下：

<img src="https://zlkqzimg-1310374208.cos.ap-chengdu.myqcloud.com/v2-4e19d89b47e21cf284644b0576e9af0f_720w.jpg" alt="img" style="zoom:80%;" />

很容易估计出两枚硬币抛掷正面的概率：
$$
\begin{array}{l}
\theta_{A}=24 / 30=0.8 \\
\theta_{B}=9 / 20=0.45
\end{array}
$$

- 现在加入隐变量，抹去每次投掷的硬币标记，即不知道这次投的是A还是B：

<img src="https://zlkqzimg-1310374208.cos.ap-chengdu.myqcloud.com/v2-caa896173185a8f527c037c122122258_720w.jpg" alt="img" style="zoom:80%;" />

这种情况又如何估计$\theta_A, \theta_B$呢。我们多出了一个隐变量$$Z = \{z_1, ..., z_5\}$$，代表每次投掷的硬币类型。我们需要Z才能估计参数$\theta_A, \theta_B$，而又需要$\theta_A, \theta_B$才能估计Z。其解决方法就是先随机初始化$\theta_A, \theta_B$ ，然后用去估计 Z， 然后基于 Z 按照最大似然概率去估计新的$\theta_A, \theta_B$，循环至收敛。

- 现在随机初始化$$\theta_A = 0.6, \theta_B = 0.5$$，以第一轮投掷来说，硬币A投出5H5T结果的概率是$$C_{10}^5 0.6^5 * 0.4^5$$，而B投出5H5T的概率为$$C_{10}^5 0.5^5 * 0.5^5$$，由此可以算出本次使用A或B硬币的概率：

$$
\begin{array}{l}
P_{A}=\frac{0.6^{5} * 0.4^{5}}{\left(0.6^{5} * 0.4^{5}\right)+\left(0.5^{5} * 0.5^{5}\right)}=0.45 \\
P_{B}=\frac{0.5^{5} * 0.5^{5}}{\left(0.6^{5} * 0.4^{5}\right)+\left(0.5^{5} * 0.5^{5}\right)}=0.55
\end{array}
$$

对其他轮进行同样的操作，得到：

<img src="https://zlkqzimg-1310374208.cos.ap-chengdu.myqcloud.com/v2-b325de65a5bcac196fc0939f346410d7_720w.jpg" alt="img" style="zoom:80%;" />

**这一步我们实际上是估计出了 Z 的概率分布，这部就是 E-Step**

- 结合硬币 A 的概率和上一张投掷结果，我们利用期望可以求出硬币 A 和硬币 B 的贡献。以第二轮硬币 A 为例子，计算方式为：

$$
\begin{array}{l}
H: 0.80 * 9=7.2 \\
T: 0.80 * 1=0.8
\end{array}
$$

对其他轮和硬币B进行同样的操作，得到：

<img src="https://zlkqzimg-1310374208.cos.ap-chengdu.myqcloud.com/v2-9b6e8c50c0761c6ac19909c26e0a71d4_720w.jpg" alt="img" style="zoom:80%;" />

- 然后用极大似然估计来估计新的$\theta_A, \theta_B$：

$$
\begin{aligned}
\theta_{A} &=\frac{21.3}{21.3+8.6}=0.71 \\
\theta_{B} &=\frac{11.7}{11.7+8.4}=0.58
\end{aligned}
$$

**这步就对应了 M-Step，重新估计出了参数值。**

- 如此反复迭代，我们就可以算出最终的参数值。



### 6.3 算法流程

- 给定观测变量Y、隐变量Z，模型参数为$$\theta$$

> 1. 首先选定参数的初始值$$\theta^{(0)}$$，开始迭代
> 2. E步：在第$$i+1$$次迭代时，已知$$\theta^{(i)}$$，计算：
>
> $$
> \begin{aligned}
> Q\left(\theta, \theta^{(i)}\right) &=E_{Z}\left[\log P(Y, Z \mid \theta) \mid Y, \theta^{(i)}\right] \\
> &=\sum_{Z} \log P(Y, Z \mid \theta) P\left(Z \mid Y, \theta^{(i)}\right)
> \end{aligned}
> $$
>
> 3. M步：求得使$$Q(\theta, \theta^{(i)})$$最大化的$$\theta$$，作为$$\theta^{(i+1)}$$：
>
> $$
> \theta^{(i+1)}=\arg \max _{\theta} Q\left(\theta, \theta^{(i)}\right)
> $$
>
> 4. 重复上述的E步和M步，直至收敛

- **注意：**初始值是可以随机选择的，但是**EM算法对初值敏感**，EM有可能收敛到局部最优点



### 6.4 算法推导

- 面对一个含隐变量的概率模型，目标是最大化：

$$
\begin{aligned}
L(\theta) &=\log P(Y \mid \theta)=\log \sum_{Z} P(Y, Z \mid \theta) \\
&=\log \left(\sum_{Z} P(Y \mid Z, \theta) P(Z \mid \theta)\right)
\end{aligned}
$$

- 在第$$i+1$$次迭代时，我们是希望有所提升，即得到的$$\theta$$的似然$$L(\theta)$$要大于当前的似然$$L(\theta^{(i)})$$，所以将两者相减：

$$
\begin{aligned}
L(\theta)-L\left(\theta^{(i)}\right) &= \log \left(\sum_{Z} P(Y \mid Z, \theta) P(Z \mid \theta)\right)-\log P\left(Y \mid \theta^{(i)}\right)\\
& =\log \left(\sum_{Z} P\left(Y \mid Z, \theta^{(i)}\right) \frac{P(Y \mid Z, \theta) P(Z \mid \theta)}{P\left(Y \mid Z, \theta^{(i)}\right)}\right)-\log P\left(Y \mid \theta^{(i)}\right) \\
& \geqslant \sum_{Z} P\left(Z \mid Y, \theta^{(i)}\right) \log \frac{P(Y \mid Z, \theta) P(Z \mid \theta)}{P\left(Z \mid Y, \theta^{(i)}\right)}-\log P\left(Y \mid \theta^{(i)}\right) \\
&=\sum_{Z} P\left(Z \mid Y, \theta^{(i)}\right) \log \frac{P(Y \mid Z, \theta) P(Z \mid \theta)}{P\left(Z \mid Y, \theta^{(i)}\right) P\left(Y \mid \theta^{(i)}\right)}
\end{aligned}
$$

上述放缩用到了**Jensen不等式**

- 令：

$$
B\left(\theta, \theta^{(i)}\right) \hat{=} L\left(\theta^{(i)}\right)+\sum_{Z} P\left(Z \mid Y, \theta^{(i)}\right) \log \frac{P(Y \mid Z, \theta) P(Z \mid \theta)}{P\left(Z \mid Y, \theta^{(i)}\right) P\left(Y \mid \theta^{(i)}\right)}
$$

那么：
$$
L(\theta) \geqslant B\left(\theta, \theta^{(i)}\right)
$$
即$$B(\theta, \theta^{(i)})$$为$$L(\theta)$$的下界，并且在$$\theta=\theta^{(i)}$$时取等号：
$$
L\left(\theta^{(i)}\right)=B\left(\theta^{(i)}, \theta^{(i)}\right)
$$

- 所以，增大下界$$B(\theta, \theta^{(i)})$$，同样可以使得$$L(\theta)$$增大，而为了$$L(\theta)$$增大得最多，选择$$\theta^{(i+1)}$$使得$$B(\theta, \theta^{(i)})$$达到极大：

$$
\theta^{(i+1)}=\arg \max _{\theta} B\left(\theta, \theta^{(i)}\right)
$$

- 由上式就可以推出$$Q(\theta, \theta^{(i)})$$函数：

$$
\begin{aligned}
\theta^{(i+1)} &=\arg \max _{\theta}\left(L\left(\theta^{(i)}\right)+\sum_{Z} P\left(Z \mid Y, \theta^{(i)}\right) \log \frac{P(Y \mid Z, \theta) P(Z \mid \theta)}{P\left(Z \mid Y, \theta^{(i)}\right) P\left(Y \mid \theta^{(i)}\right)}\right) \\
&=\arg \max _{\theta}\left(\sum_{Z} P\left(Z \mid Y, \theta^{(i)}\right) \log (P(Y \mid Z, \theta) P(Z \mid \theta))\right) \\
&=\arg \max _{\theta}\left(\sum_{Z} P\left(Z \mid Y, \theta^{(i)}\right) \log P(Y, Z \mid \theta)\right) \\
&=\arg \max _{\theta} Q\left(\theta, \theta^{(i)}\right)
\end{aligned}
$$



### 6.5 直观解释

- 上方曲线为$$L(\theta)$$，下方曲线为$$B(\theta, \theta^{(i)})$$，两者在$$\theta=\theta^{(i)}$$处相等，此时执行M步：找到$$\theta^{(i+1)}=\arg \max _{\theta} B\left(\theta, \theta^{(i)}\right)$$。函数$$B(\theta, \theta^{(i)})$$的增加同时也造成了$$L(\theta)$$的增加。得到$$\theta^{(i+1)}$$后再执行E步：在$$\theta = \theta^{(i+1)}$$点重新计算Q函数，然后进行下一次迭代

![image-20221021194004500](https://zlkqzimg-1310374208.cos.ap-chengdu.myqcloud.com/image-20221021194004500.png)