---
title: 常用损失函数和评估模型的指标
math: true
date: 2021-11-13
---



# 1 常用损失函数

### 1.1 0-1损失函数

$$
L(y, \hat{y}) = \begin{cases}
1 & y\neq \hat{y}\\
0 & y = \hat{y}
\end{cases}
$$

- 0-1损失函数直接对应分类判断错误的个数，但是它是一个非凸函数，不太适用
- 感知机就是用的这种损失函数。但是相等这个条件太过严格，因此可以放宽条件，即满足$|y - \hat{y}| < T$时认为相等，即：

$$
L(y, \hat{y}) = \begin{cases}
1 & |y - \hat{y}| \geq T\\
0 & |y - \hat{y}| < T
\end{cases}
$$



### 1.2 均方差损失函数（MSE）

$$
J_{MSE} = \frac{1}{N} \sum_{i = 1}^N(y_i - \hat{y_i})^2
$$

- 也称L2 Loss



##### 1.2.1 证明

假设预测值和真实值的误差$\epsilon$服从标准正态分布，则给定一个$x_i$输出真实值$y_i$的概率为：
$$
p(\hat y_i = y_i|x_i) = p(\hat y_i = f(x_i) + \epsilon) | x_i) = p(\epsilon) = \frac{1}{\sqrt{2\pi}}exp(-\frac{(y_i - \hat{y_i})^2}{2})
$$
其实就是极大似然估计，我们要寻找一组参数，使$p(y_i|x_i)$最大

进一步对所有样本，由于他们相互独立，所以所有样本都正好取到真实值$y$的概率为：
$$
L(x, y) = \prod_{i = 1}^N\frac{1}{\sqrt{2\pi}}exp(-\frac{(y_i - \hat{y_i})^2}{2})
$$
现在我们就要使$L(x, y)$最大，为了方便计算，我们取对数：
$$
LL(x, y) = log(L(x, y)) = -\frac{N}{2}log2\pi - \frac{1}{2}\sum_{i = 1}^N(y_i - \hat{y_i})^2
$$
把第一项无关项去掉，再取负：
$$
NLL(x, y) = \frac{1}{2}\sum_{i = 1}^N(y_i - \hat{y_i})^2
$$
即得到均方差形式



##### 1.2.2 为什么可以用极大似然

**在模型输出与真实值的误差服从高斯分布的假设下，最小化均方差损失函数与极大似然估计本质上是一致的，拟合数据最好的情况就是所有的$y_i = \hat{y_i}$，即每个样本的$p(y_i|x_i)$取最大，即$L(x, y)$取最大，由于对数运算不改变单调性，并且最后取了个负值，所以即$NLL(x, y)$取最小**



### 1.3 平均绝对误差损失（MAE）

$$
J_{MAE} = \frac{1}{N}\sum_{i = 1}^N|y_i - \hat{y_i}|
$$

- 也称L1 Loss



##### 1.3.1 拉普拉斯分布

$$
f(x|\mu, b) = \frac{1}{2b}exp(-\frac{|x - \mu|}{b})
$$

期望值：$\mu$             方差：$2b^2$

<img src="https://i.loli.net/2021/11/08/yWY3hI4ioKpADRF.png" alt="Laplace_distribution_pdf" style="zoom: 25%;" />



##### 1.3.2 证明

假设预测值和真实值的误差服从拉普拉斯分布（$\mu = 0, b = 1$）
$$
p(y_i | x_i) = \frac{1}{2}exp(-{|y_i - \hat{y_i}|})
$$
剩余证明和上述MSE证明过程一样



##### 1.3.3 MSE和MAE的区别：

- **MSE 损失相比 MAE 通常可以更快地收敛**

关于$\hat{y_i}$求导时，MSE为$-(y_i - \hat{y_i})$，MAE为$\pm1$，即 MSE 的梯度的 scale 会随误差大小变化，而 MAE 的梯度的 scale 则一直保持为 1，即便在绝对误差很小的时候 MAE 的梯度 scale 也同样为 1，这实际上是非常不利于模型的训练的（当然也可以通过调整学习率缓解这个问题，但总体来说还是MSE更快）。

- **MAE对于离群值更加健壮，即更加不易受到离群值影响**

1. 由于MAE 损失与绝对误差之间是线性关系，MSE 损失与误差是平方关系，当误差非常大的时候，MSE 损失会远远大于 MAE 损失
2. MSE 假设了误差服从正态分布，MAE 假设了误差服从拉普拉斯分布。拉普拉斯分布本身对于离群值更加健壮



##### 1.3.4 MSE和MAE的收敛

- MSE收敛于均值

将$\hat{y_i}$设为变量$t$：
$$
J_{MSE} = \frac{1}{N}\sum_{i = 1}^N(t - y_i)^2
$$
关于$t$求导：
$$
\frac{\partial J}{\partial t} = \frac{2}{N}\sum_{i = 1}^N(t - y_i) = 0
$$
求得：
$$
t = \frac{1}{N}\sum_{i = 1}^Ny_i = E(y)
$$

- MAE收敛于中值

将$\hat{y_i}$设为变量$t$：
$$
J_{MAE} = \frac{1}{N}\sum_{i = 1}^N|t - y_i|
$$
关于$t$求导：
$$
\frac{\partial J}{\partial t} = \frac{1}{N}\sum_{i = 1}^Nsgn(t - y_i) = 0
$$
显然在该种情况下应该取$t$为中值



### 1.4 Huber Loss

- 上面介绍了MSE和MAE，他们各有各的优缺点，MSE 损失收敛快但容易受 outlier 影响，MAE 对 outlier 更加健壮但是收敛慢，而Huber Loss则是将两者结合起来，原理很简单，就是误差接近 0 时使用 MSE，误差较大时使用 MAE：

$$
J_{huber} = \frac{1}{N} \sum_{i=1}^{N} \mathbb{I}_{\left|y_{i}-\hat{y}_{i}\right| \leq \delta} \frac{\left(y_{i}-\hat{y}_{i}\right)^{2}}{2}+\mathbb{I}_{\left|y_{i}-\hat{y}_{i}\right|>\delta}\left(\delta\left|y_{i}-\hat{y}_{i}\right|-\frac{1}{2} \delta^{2}\right)
$$

- 前半部分是MSE部分，后半部分是MAE部分，超参数$\delta$为两个部分的连接处
- MAE部分为$\delta |y_i - \hat{y_i}| - \frac{1}{2}\delta ^2$是为了在$|y_i - \hat{y_i}| = \delta$ 端点处连续可导

![超参数为1的Huber Loss](https://i.loli.net/2021/11/09/e6FQMBY42PDGxtI.png)

- Huber Loss 结合了 MSE 和 MAE 损失，在误差接近 0 时使用 MSE，使损失函数可导并且梯度更加稳定；在误差较大时使用 MAE 可以降低 outlier 的影响，使训练对 outlier 更加健壮。缺点是需要额外地设置一个$\delta$超参数。



### 1.5 分位数损失（Quantile Loss）

$$
J_{\text {quant }}=\frac{1}{N} \sum_{i=1}^{N} \mathbb{I}_{\hat{y}_{i} \geq y_{i}}(1-r)\left|y_{i}-\hat{y}_{i}\right|+\mathbb{I}_{\hat{y}_{i}<y_{i}} r\left|y_{i}-\hat{y}_{i}\right|
$$

- 这是一个分段函数，这个损失函数是一个分段的函数 ，将$\hat{y_i} \geq y_i$（高估） 和$\hat{y_i} < y_i$（低估) 两种情况分开来，并分别给予不同的系数
- 分位数损失实现了分别用不同的系数（r和1-r）控制高估和低估的损失
- 特别地，当$r = 0.5$时分位数损失退化为 MAE 损失

![Quantile Loss](https://i.loli.net/2021/11/09/BvpTeXqWFYRKoMU.png)



### 1.6 交叉熵损失（Cross Entropy Loss）

- 上文介绍的几种损失函数都是适用于回归问题损失函数，对于分类问题，最常用的损失函数是交叉熵损失函数 

##### 1.6.1 二分类

$$
J_{C E}=-\sum_{i=1}^{N}\left(y_{i} \log \left(\hat{y}_{i}\right)+\left(1-y_{i}\right) \log \left(1-\hat{y}_{i}\right)\right)
$$

![二分类的交叉熵](https://i.loli.net/2021/11/09/hPt1nITJ624Llfp.png)

- 证明：

在二分类中我们通常将输出结果用sigmoid映射到区间$(0, 1)$，并将其作为该类的概率，由于只有两类，所以给定$x_i$求出类别为1或0的概率分别为：
$$
\begin{gather}
p(y_i = 1|x_i) = \hat{y_i} \\
p(y_i = 0|x_i) = 1 - \hat{y_i}
\end{gather}
$$
合并成一个式子：
$$
p(y_i|x_i) = (\hat{y_i})^{y_i}(1 - \hat{y_i})^{1 - y_i}
$$
由于各数据点独立同分布，则似然可以表示为：
$$
L(x, y) = \prod_{i=1}^{N}\left(\hat{y}_{i}\right)^{y_{i}}\left(1-\hat{y}_{i}\right)^{1-y_{i}}
$$
取负对数：
$$
N L L(x, y)=J_{C E}=-\sum_{i=1}^{N}\left(y_{i} \log \left(\hat{y}_{i}\right)+\left(1-y_{i}\right) \log \left(1-\hat{y}_{i}\right)\right)
$$


##### 1.6.2 多分类

在多分类的任务中，交叉熵损失函数的推导思路和二分类是一样的，变化的地方是真实值$y_i$现在是一个 One-hot 向量，同时模型输出的压缩由原来的 Sigmoid 函数换成 Softmax 函数
$$
J_{C E}=-\sum_{i=1}^{N} \sum_{k=1}^{K} y_{i}^{k} \log \left(\hat{y}_{i}^{k}\right)
$$
因为$y_i$是一个One-hot向量，所以还可以写为：
$$
J_{C E}=-\sum_{i=1}^{N} y_{i}^{c_{i}} \log \left(\hat{y}_{i}^{c_{i}}\right)
$$
其中$c_i$为样本$x_i$的目标类

- 证明：

对于一个样本，分类正确的概率为：
$$
p(y_i|x_i) = \prod_{k=1}^{K}\left(\hat{y}_{i}^{k}\right)^{y_{i}^{k}}
$$
（其中$y_i^k和\hat{y_i}^k$为该向量的第k维）

因为所有样本相互，所有相乘再取负对数即可得到：
$$
N L L(x, y)=J_{C E}=-\sum_{i=1}^{N} \sum_{k=1}^{K} y_{i}^{k} \log \left(\hat{y}_{i}^{k}\right)
$$


### 1.7 合页损失（Hinge Loss）

- Hinge Loss也是一种二分类损失函数

$$
J_{\text {hinge }}=\sum_{i=1}^{N} \max \left(0,1-\operatorname{sgn}\left(y_{i}\right) \hat{y}_{i}\right)
$$

下图是$y$为正类， 即$sgn(y) = 1$时，不同输出的合页损失示意图：

![image-20211109225642368](https://i.loli.net/2021/11/09/KngeQOwp54JZRMf.png)

- 可以看到当$y$为正类时，模型输出负值会有较大的惩罚，当模型输出为正值且在$(0, 1)$区间时还会有一个较小的惩罚。即合页损失不仅惩罚预测错的，并且对于预测对了但是置信度不高的也会给一个惩罚，只有置信度高的才会有零损失。**使用合页损失直觉上理解是要找到一个决策边界，使得所有数据点被这个边界正确地、高置信地被分类**
- **Hinge Loss常用在支持向量机（SVM）中，在SVM的软间隔中替换数学性质不好的0/1损失**

- **Hinge Loss变种：**有些时候我们关注的并不是单个样本的分类结果，而是两个样本之间的相似性，所以会使用：

$$
\ell= \max(0, m + score(pos\_pair) - score(neg\_pair))
$$

其中两个score分别为正负样本对的得分，m是间隔参数margin，目的是**希望正样本分数越高越好，负样本分数越低越好，但二者得分之差最多到m就足够了，差距增大并不会有任何奖励。这样能够拉开正负样本间的差距，更好区分正负样本**



# 2 评估模型的指标

### 2.1 基本概念

![image-20211109233859657](https://i.loli.net/2021/11/09/OCNnaMs2ceBQIJz.png)



### 2.2 查准率和查全率

$$
查准率 P（Precision） = \frac{TP}{TP + FP}
$$


$$
查全率 R（Recall） = \frac{TP}{TP + FN}
$$

- 查准率可以直观理解为所有预测为正项的样本中有多少是真正的正项
- 查全率可以直观理解为所有label是正项的样本中有多少被成功预测出来了
- 理想情况下，查准率和查全率两者都越高越好。**然而事实上这两者在某些情况下是矛盾的，一般来说，查准率高时，查全率低；查确率低时，查全率高**



### 2.3 准确率和错误率

准确率：
$$
accuracy = \frac{TP + TF}{TP + TN + FP + FN}
$$

- 即有多少样本被分类正确

而错误率：
$$
errorrate = 1 - accuracy
$$


### 2.4 P-R曲线

<img src="https://i.loli.net/2021/11/10/zV1Sj4HyYfD3G5e.png" alt="image-20211110000609300" style="zoom: 80%;" />

- P-R曲线直观地显示出学习器在样本总体上地查全率、查准率，在进行比较时，**若一个学习器的P-R曲线被另一个学习器曲线“完全包住”，则可以断言后者的性能一定优于前者，如上图的B性能优于C，而A、B不一定**
- 平衡点（BEP）时$P = R$时的取值，如上图A的BEP为0.8，而如果基于BEP比较，可知A优于B



### 2.5 F函数

BEP还是过于简化了些，更常用得是F1度量，我们可以取P和R的调和平均：
$$
\frac{2}{F_1} = \frac{1}{P} + \frac{1}{R}
$$
求得：
$$
F1 = \frac{2PR}{P + R}
$$
但是在许多应用中我们对查准率和查全率得重视程度不同，所以可以给予P和R不同的权重，取P和R的加权调和平均：
$$
\frac{1}{F_{\beta}} = \frac{1}{1 + \beta ^2}(\frac{1}{P} + \frac{\beta ^2}{R})
$$
求得：
$$
F_{\beta} = \frac{(1 + \beta ^2)PR}{\beta ^2P + R}
$$

- $\beta > 0$度量了查全率和查准率的相对重要性，$\beta = 1$退化为标准的F1，$\beta > 1$查全率有更大影响，$\beta < 1$查准率有更大影响



### 2.6 ROC与AUC

##### 2.6.1 基本概念

- 大多二分类问题是将输出的预测值与一个**分类阈值（threshold）**进行比较，若预测值大于阈值则为正类，反之则为负类

- 根据预测值，我们可将测试样本进行排序，根据预测值由大到小，“最可能”是正例的排在前面，“最不可能”是正例的排到后面。**这样，分类过程就相当于以中间某个截断点（也就是分类阈值）将样本分为两部分，前一部分判定为正例，后一部分判定为反例**

- 在不同的任务中，我们我们可以根据任务需求采取不同的截断点。例如如更重视查准率，可以将截断点设置靠前，更注重查全率，可以将截断点靠后
- 而我们根据预测值进行排序后，按顺序将样本逐个作为正例进行预测，每次计算出**真正例率（TPR）**和**假正例率（FPR）**，以他们为横纵坐标就得到了**ROC曲线**



##### 2.6.2 ROC曲线

- 首先介绍真正例率和假正例率：

$$
\begin{gather}
TPR = \frac{TP}{TP + FN}, \\
FPR = \frac{FP}{TN + FP}
\end{gather}
$$

- ROC曲线：

首先将分类阈值设最大，则所有类都被分类为负类，TPR和FPR都为0，然后每次将分类阈值设为下一个样本点的预测值（按预测值由大到小进行排序），记录每次的TPR和FPR，组成ROC曲线

![image-20211110140633061](https://i.loli.net/2021/11/10/TUMHuC3N9rX18iz.png)

但是现实中我们是基于有限个样本画的图，所以不会产生这么平滑的曲线，更多情况应该像下图：

![image-20211110140853013](https://i.loli.net/2021/11/10/xG1TrPNfyimzq7Q.png)

- 基于ROC的比较方法

>如果一个学习器的ROC曲线完全被另一个学习器的”包住“，则后者性能优于前者
>
>若两者的曲线交叉，则可以通过ROC曲线所包裹的面积进行判断，即**AUC**



##### 2.6.3 AUC

- **AUC就是ROC曲线下的面积**，假定ROC曲线是由坐标为$$\left(x_{1}, y_{1}\right),\left(x_{2}, y_{2}\right),\left(x_{3}, y_{3}\right), \cdots,\left(x_{m}, y_{m}\right)$$的点按序连接而形成，则AUC为：

$$
A U C=\frac{1}{2} \sum_{i=1}^{m-1}\left(x_{i+1}-x_{i}\right)\left(y_{i}+y_{i+1}\right)
$$

- 从Mann–Whitney U statistic的角度来解释，AUC就是从所有1样本中随机选取一个样本， 从所有0样本中随机选取一个样本，然后根据你的分类器对两个随机样本进行预测，把1样本预测为1的概率为p1，把0样本预测为1的概率为p0，p1>p0的概率就等于AUC， 即**AUC是指随机给定一个正样本和一个负样本，分类器输出该正样本为正的那个概率值比分类器输出该负样本为正的那个概率值要大的可能性**

- **所以AUC反应的是分类器对样本的排序能力**

证明：

设所有正类的集合$X = \{ \hat{X_1}, \hat{X_2}, ..., \hat{X_m}\}$和负类的集合$Y = \{ \hat{Y_1}, \hat{Y_2}, ..., \hat{Y_n}\}$，其中是每个样本对应的预测值，设分类阈值为c，$F_X(x)$和$F_Y(y)$分别为X和Y的分布函数，则$TPR(c) = 1 - F_X(c)$，$FPR(c) = 1 - F_Y(c)$

设$t = FPR(c)$， 则$c = F_Y^{-1}(1 - t)$，则$ROC(t) = 1 - F_X(F_Y^{-1}(1 - t))$

则：
$$
\begin{gather}
AUC = \int_0^1ROC(t)dt \\
=\int_0^1 [1 - F_X(F_Y^{-1}(1 - t))] dt \\
=\int_0^1 [1 - F_X(F_Y^{-1}(t))] dt \\
=\int_{-\infty}^{+\infty} [1 - F_X(y)] dF_Y(y) \\
=\int_{-\infty}^{+\infty}P(X > y)f_Y(y)dy \\
=\int_{-\infty}^{+\infty}P(X > y, Y = y)dy \\
=P(X > Y)
\end{gather}
$$


##### 2.6.4 使用ROC和AUC的优点

- **AUC的计算方法同时考虑了学习器对于正例和负例的分类能力，在样本不平衡（正负类样本不相同）的情况下，依然能够对分类器做出合理的评价**

$$
\begin{gather}
TPR = P(\hat{Y} = 1 | Y = 1), \\
FPR = P(\hat{Y} = 1 | Y = 0)
\end{gather}
$$

**由上式可得：无论Y的真实概率是多少， 都不会影响TPR和FPR**

而PR曲线更关注正例

- ROC曲线能很容易的查出任意阈值对学习器的泛化性能影响，有助于选择最佳的阈值。ROC曲线越靠近左上角，模型的查全率就越高。最靠近左上角的ROC曲线上的点是分类错误最少的最好阈值，其假正例和假反例总数最少



- 上面几种评估方法都是**用于分类**的评估方法，而在**回归问题**当中，这些一般是不适用的，回归问题中我们比较常用的评估方法有一下两种



### 2.7 平方根误差（RMSE）

$$
RMSE = \sqrt{\frac{\sum_{i = 1}^n(y_i - \hat y_i)^2}{n}}
$$

- 其实RMSE就是MSE开了个根，但是我们做这样的处理能让**误差和结果值在同一个数量级上，这样能更直观有效的反应拟合程度**
- 但是RMSE有着和MSE一样的缺点，那就是**对离群值十分敏感，健壮性很差**
- 比如在实际应用中，有可能在对于预测某些剧集的流量时，以便进行广告投放，在95%的区间内的预测误差都十分低，比如小于1%，这是相当不错的预测结果。但是在总体上，无论运用何种模型，RMSE可能都一直居高不下。**原因是可能在剩余的5%区间里有非常严重的离群点，比如某些冷门剧、新上映的剧**
- 对此我们可以选择对数据进行处理，或者换一种模型指标



### 2.8 平均绝对百分比误差（MAPE）

$$
MAPE = \sum_{i = 1}^n |\frac{y_i - \hat{y}_i}{y_i}| \times \frac{100}{n}
$$

- 相比RMSE， MAPE相当于把每个点的误差进行了归一化，降低了个别离群点带来的影响

