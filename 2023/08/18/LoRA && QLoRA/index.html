

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/favicon.png">
  <link rel="icon" href="/img/favicon.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="description" content="bia">
  <meta name="author" content="zlk">
  <meta name="keywords" content="">
  <meta name="description" content="1 前置假设 LoRA的灵感来自于另一篇论文：Intrinsic Dimensionality Explains the Effectiveness of Language Model Fine-Tuning 这篇论文认为，在参数更新时，不需要对参数的整个向量空间进行更新，只需要随机映射到他的一个子空间（一般都是直接指列空间的子空间），在这个子空间上参数更新，就能达到十分接近的效果，能达到这个要求">
<meta property="og:type" content="article">
<meta property="og:title" content="LoRA &amp;&amp; QLoRA">
<meta property="og:url" content="https://zlkqz.github.io/2023/08/18/LoRA%20&&%20QLoRA/index.html">
<meta property="og:site_name" content="ZLK">
<meta property="og:description" content="1 前置假设 LoRA的灵感来自于另一篇论文：Intrinsic Dimensionality Explains the Effectiveness of Language Model Fine-Tuning 这篇论文认为，在参数更新时，不需要对参数的整个向量空间进行更新，只需要随机映射到他的一个子空间（一般都是直接指列空间的子空间），在这个子空间上参数更新，就能达到十分接近的效果，能达到这个要求">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://zlkqzimg-1310374208.cos.ap-chengdu.myqcloud.com/image-20230808143823489.png">
<meta property="og:image" content="https://zlkqzimg-1310374208.cos.ap-chengdu.myqcloud.com/image-20230808172556109.png">
<meta property="og:image" content="https://zlkqzimg-1310374208.cos.ap-chengdu.myqcloud.com/image-20230808172638176.png">
<meta property="og:image" content="https://zlkqzimg-1310374208.cos.ap-chengdu.myqcloud.com/image-20230808172719697.png">
<meta property="og:image" content="https://zlkqzimg-1310374208.cos.ap-chengdu.myqcloud.com/image-20230808172934424.png">
<meta property="og:image" content="https://zlkqzimg-1310374208.cos.ap-chengdu.myqcloud.com/image-20230808173756918.png">
<meta property="og:image" content="https://zlkqzimg-1310374208.cos.ap-chengdu.myqcloud.com/image-20230808174526241.png">
<meta property="og:image" content="https://zlkqzimg-1310374208.cos.ap-chengdu.myqcloud.com/image-20230810153943129.png">
<meta property="og:image" content="https://zlkqzimg-1310374208.cos.ap-chengdu.myqcloud.com/image-20230810161204970.png">
<meta property="og:image" content="https://zlkqzimg-1310374208.cos.ap-chengdu.myqcloud.com/image-20230810162338348.png">
<meta property="og:image" content="https://zlkqzimg-1310374208.cos.ap-chengdu.myqcloud.com/image-20230829160539803.png">
<meta property="og:image" content="https://zlkqzimg-1310374208.cos.ap-chengdu.myqcloud.com/image-20230829174543969.png">
<meta property="og:image" content="https://zlkqzimg-1310374208.cos.ap-chengdu.myqcloud.com/image-20230829175203934.png">
<meta property="og:image" content="https://zlkqzimg-1310374208.cos.ap-chengdu.myqcloud.com/image-20230829175357381.png">
<meta property="og:image" content="https://zlkqzimg-1310374208.cos.ap-chengdu.myqcloud.com/image-20230829191239069.png">
<meta property="og:image" content="https://zlkqzimg-1310374208.cos.ap-chengdu.myqcloud.com/image-20230829191321959.png">
<meta property="og:image" content="https://zlkqzimg-1310374208.cos.ap-chengdu.myqcloud.com/image-20230829191406666.png">
<meta property="article:published_time" content="2023-08-17T16:00:00.000Z">
<meta property="article:modified_time" content="2023-08-29T11:36:02.056Z">
<meta property="article:author" content="zlk">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://zlkqzimg-1310374208.cos.ap-chengdu.myqcloud.com/image-20230808143823489.png">
  
  <title>LoRA &amp;&amp; QLoRA - ZLK</title>

  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/github-markdown-css@4/github-markdown.min.css" />
  <link  rel="stylesheet" href="/lib/hint/hint.min.css" />

  
    
    
      
      <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@10/styles/github-gist.min.css" />
    
  

  
    <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3/dist/jquery.fancybox.min.css" />
  


<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_ba1fz6golrf.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_kmeydafke9r.css">


<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->


  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    var CONFIG = {"hostname":"zlkqz.github.io","root":"/","version":"1.8.12","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"right","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"copy_btn":true,"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname"}},"search_path":"/local-search.xml"};
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
<meta name="generator" content="Hexo 5.4.0"></head>


<body>
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>ZLK</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="banner" id="banner" parallax=true
         style="background: url('/img/default.png') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="page-header text-center fade-in-up">
            <span class="h2" id="subtitle" title="LoRA &amp;&amp; QLoRA">
              
            </span>

            
              <div class="mt-3">
  
  
    <span class="post-meta">
      <i class="iconfont icon-date-fill" aria-hidden="true"></i>
      <time datetime="2023-08-18 00:00" pubdate>
        2023年8月18日 凌晨
      </time>
    </span>
  
</div>

<div class="mt-1">
  
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      6.4k 字
    </span>
  

  
    <span class="post-meta mr-2">
      <i class="iconfont icon-clock-fill"></i>
      
      
      20 分钟
    </span>
  

  
  
    
      <!-- 不蒜子统计文章PV -->
      <span id="busuanzi_container_page_pv" style="display: none">
        <i class="iconfont icon-eye" aria-hidden="true"></i>
        <span id="busuanzi_value_page_pv"></span> 次
      </span>
    
  
</div>

            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div class="py-5" id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">LoRA &amp;&amp; QLoRA</h1>
            
            <div class="markdown-body">
              <h1 id="1-前置假设"><a href="#1-前置假设" class="headerlink" title="1 前置假设"></a>1 前置假设</h1><ul>
<li>LoRA的灵感来自于另一篇论文：Intrinsic Dimensionality Explains the Effectiveness of Language Model Fine-Tuning</li>
<li>这篇论文认为，<strong>在参数更新时，不需要对参数的整个向量空间进行更新，只需要随机映射到他的一个子空间（一般都是直接指列空间的子空间），在这个子空间上参数更新，就能达到十分接近的效果，能达到这个要求的最小子空间维度即为“intrinsic dimension”</strong></li>
<li>设原参数为<script type="math/tex">W \in \mathbb{R}^{D \times m}</script>，其列空间为<script type="math/tex">\theta^m = [\theta_0, ..., \theta_{m-1}]</script>，那么参数更新公式则变为了：</li>
</ul>
<script type="math/tex; mode=display">
\theta^m = \theta^m + P(\theta^n)</script><p>其中<script type="math/tex">\theta^n \in \mathbb{R}^{D \times n}</script>表示映射后的子空间，P表示<script type="math/tex">\mathbb{R}^n \rightarrow \mathbb{R}^m</script>的随机映射，用矩阵表示为右乘<script type="math/tex">M \in \mathbb{R}^{n \times m}</script>。<strong>子空间维度n即为“intrinsic dimension”</strong></p>
<ul>
<li><p>随机映射P有多种，包括随机线性映射、随机稀疏线性映射、Fastfood Transform等。并且<script type="math/tex">\theta^n</script>是初始化为全0以保持开始时和预训练权重一致</p>
</li>
<li><p>这篇文章还有其他结论：</p>
</li>
</ul>
<blockquote>
<ol>
<li>预训练可以降低intrinsic dimension</li>
<li>大模型通常拥有更小的intrinsic dimension</li>
</ol>
</blockquote>
<h1 id="2-LoRA"><a href="#2-LoRA" class="headerlink" title="2 LoRA"></a>2 LoRA</h1><h3 id="2-1-LoRA定义"><a href="#2-1-LoRA定义" class="headerlink" title="2.1 LoRA定义"></a>2.1 LoRA定义</h3><ul>
<li><p>LoRA认为<strong>权重的更新量同样拥有一个intrinsic dimension（记为r），所以将权重更新量<script type="math/tex">\Delta W</script>分解为两个矩阵<script type="math/tex">\Delta W = BA</script></strong></p>
</li>
<li><p>在计算时，将原预训练权重的activation加上这个BA的activation，得到新的activation：</p>
</li>
</ul>
<script type="math/tex; mode=display">
h=W_{0} x+\Delta W x=W_{0} x+B A x</script><p>其中<script type="math/tex">W_0 \in \mathbb{R}^{d \times k}</script>，<script type="math/tex">B \in \mathbb{R}^{d \times r}</script>表示映射后的子空间参数矩阵，<script type="math/tex">A \in \mathbb{R}^{r \times k}</script>表示两个空间的映射矩阵，并且<script type="math/tex">r \ll \min (d, k)</script></p>
<ul>
<li>在参数初始化时是将B设为全0，A服从<script type="math/tex">\mathcal{N}\left(0, \sigma^{2}\right)</script>：</li>
</ul>
<p><img src="https://zlkqzimg-1310374208.cos.ap-chengdu.myqcloud.com/image-20230808143823489.png" srcset="/img/loading.gif" lazyload alt="image-20230808143823489" style="zoom:60%;" /></p>
<h3 id="2-2-LoRA的优点"><a href="#2-2-LoRA的优点" class="headerlink" title="2.2 LoRA的优点"></a>2.2 LoRA的优点</h3><ul>
<li><strong>在训练时，是将原参数冻结，然后只更新A、B矩阵</strong>，由于<script type="math/tex">r \ll \min (d, k)</script>，所以用LoRA微调，需要更新的参数很少，并且尽管可更新参数变小了，但是效果却不差</li>
<li>LoRA没有像Adapter那样的额外推理时间消耗，<strong>在推理部署时，是直接将BA的结果加到原参数<script type="math/tex">W_0</script>上，再部署上去</strong></li>
</ul>
<h3 id="2-3-对比实验"><a href="#2-3-对比实验" class="headerlink" title="2.3 对比实验"></a>2.3 对比实验</h3><ul>
<li>LoRA可以应用的地方有5个，分别是Attention Layer里的<script type="math/tex">W_q, W_k, W_v,W_o</script>矩阵，以及MLP中的权重矩阵。<strong>本次实验并未对MLP的权重矩阵进行LoRA优化</strong></li>
<li><strong>并且在大部分对比实验中，都是仅对<script type="math/tex">W_q, W_v</script>进行<script type="math/tex">r=4</script>的优化</strong></li>
</ul>
<h5 id="2-3-1-和其他微调方法的对比"><a href="#2-3-1-和其他微调方法的对比" class="headerlink" title="2.3.1 和其他微调方法的对比"></a>2.3.1 和其他微调方法的对比</h5><ul>
<li>RoBERTa结果：</li>
</ul>
<p><img src="https://zlkqzimg-1310374208.cos.ap-chengdu.myqcloud.com/image-20230808172556109.png" srcset="/img/loading.gif" lazyload alt="image-20230808172556109" style="zoom:40%;" /></p>
<ul>
<li>GPT-2结果：</li>
</ul>
<p><img src="https://zlkqzimg-1310374208.cos.ap-chengdu.myqcloud.com/image-20230808172638176.png" srcset="/img/loading.gif" lazyload alt="image-20230808172638176" style="zoom:40%;" /></p>
<ul>
<li>GPT-3结果：</li>
</ul>
<p><img src="https://zlkqzimg-1310374208.cos.ap-chengdu.myqcloud.com/image-20230808172719697.png" srcset="/img/loading.gif" lazyload alt="image-20230808172719697" style="zoom:40%;" /></p>
<ul>
<li>此外，还对比了当可训练参数逐渐增多时，各种微调方法的结果变化（GPT-3上）：</li>
</ul>
<p><img src="https://zlkqzimg-1310374208.cos.ap-chengdu.myqcloud.com/image-20230808172934424.png" srcset="/img/loading.gif" lazyload alt="image-20230808172934424" style="zoom:50%;" /></p>
<h5 id="2-3-2-对哪些矩阵采用LoRA"><a href="#2-3-2-对哪些矩阵采用LoRA" class="headerlink" title="2.3.2 对哪些矩阵采用LoRA"></a>2.3.2 对哪些矩阵采用LoRA</h5><ul>
<li>作者在相同的可训练参数量的情况下，实验了不同的矩阵和不同的r：</li>
</ul>
<p><img src="https://zlkqzimg-1310374208.cos.ap-chengdu.myqcloud.com/image-20230808173756918.png" srcset="/img/loading.gif" lazyload alt="image-20230808173756918" style="zoom:45%;" /></p>
<ul>
<li>可以发现，<strong>同时对<script type="math/tex">W_q, W_v</script>进行优化，取得的效果最好</strong></li>
<li>并且对比单用<script type="math/tex">W_q</script>或者单用<script type="math/tex">W_k</script>的情况，发现<strong>对于每个矩阵<script type="math/tex">r=4</script>已经能获取足够的特征，这时将LoRA应用更多的矩阵比单纯提升<script type="math/tex">r</script>更有用</strong></li>
</ul>
<h5 id="2-3-3-最佳r"><a href="#2-3-3-最佳r" class="headerlink" title="2.3.3 最佳r"></a>2.3.3 最佳r</h5><ul>
<li>作者实验了应用不同的矩阵和不同的r：</li>
</ul>
<p><img src="https://zlkqzimg-1310374208.cos.ap-chengdu.myqcloud.com/image-20230808174526241.png" srcset="/img/loading.gif" lazyload alt="image-20230808174526241" style="zoom:45%;" /></p>
<ul>
<li>表明在很小的r上，LoRA已经能够取得很好的结果</li>
</ul>
<h3 id="2-4-Empirical-Analysis"><a href="#2-4-Empirical-Analysis" class="headerlink" title="2.4 Empirical Analysis"></a>2.4 Empirical Analysis</h3><h5 id="2-4-1-如何对比子空间的相似度"><a href="#2-4-1-如何对比子空间的相似度" class="headerlink" title="2.4.1 如何对比子空间的相似度"></a>2.4.1 如何对比子空间的相似度</h5><ul>
<li>给定两个矩阵<script type="math/tex">A, B</script>，而<script type="math/tex">U_A^i \in \mathbb{R}^{d \times i}</script>表示A的左或右奇异矩阵的前<script type="math/tex">i</script>列组成的矩阵，<script type="math/tex">U_B^j \in \mathbb{R}^{d \times j}</script>同理，则这两个奇异矩阵的子空间的相似度可以定义为：</li>
</ul>
<script type="math/tex; mode=display">
\phi(A, B, i, j)=\psi\left(U_{A}^{i}, U_{B}^{j}\right)=\frac{\left\|U_{A}^{i \top} U_{B}\right\|_{F}^{2}}{\min \{i, j\}}</script><ul>
<li>具体到LoRA上面，<script type="math/tex">\Delta W = BA</script>，我们对子空间的分析可以采用<strong>B的左奇异矩阵</strong>或者<strong>A的右奇异矩阵</strong>，论文是采用后者来分析的</li>
</ul>
<h5 id="2-4-2-不同r所产生的子空间"><a href="#2-4-2-不同r所产生的子空间" class="headerlink" title="2.4.2 不同r所产生的子空间"></a>2.4.2 不同r所产生的子空间</h5><ul>
<li>作者采用相同的预训练权重，用<script type="math/tex">r=8</script>和<script type="math/tex">r=64</script>分别微调了一遍，并得到了两个A矩阵<script type="math/tex">A_{r=8}, A_{r=64}</script>，以及他们的右奇异矩阵<script type="math/tex">U_{A_{r=8}}, U_{A_{r=64}}</script>，并计算他们不同子空间的相似度：</li>
</ul>
<script type="math/tex; mode=display">
\phi\left(A_{r=8}, A_{r=64}, i, j\right)=\frac{\left\|U_{A_{r=8}}^{i \top} U_{A_{r=64}}^{j}\right\|_{F}^{2}}{\min (i, j)} \in[0,1]</script><ul>
<li>得到以下结果：</li>
</ul>
<p><img src="https://zlkqzimg-1310374208.cos.ap-chengdu.myqcloud.com/image-20230810153943129.png" srcset="/img/loading.gif" lazyload alt="image-20230810153943129" style="zoom:50%;" /></p>
<p>右边两图对应左边两图的左下角空白处</p>
<ul>
<li>分析结论：<strong>在<script type="math/tex">i, j</script>较小时，是由top的几个奇异向量组成的子空间，在不同的r下，这个子空间的相似度是非常高的（特别是在<script type="math/tex">i=1</script>或<script type="math/tex">j=1</script>时，子空间的相似度甚至大于0.5）。说明top的几个奇异向量组成的子空间才是最主要的，这也解释了为什么GPT-3用<script type="math/tex">r=1</script>都能取得很不错的结果</strong></li>
</ul>
<h5 id="2-4-3-Delta-W-q和-Delta-W-v的对比"><a href="#2-4-3-Delta-W-q和-Delta-W-v的对比" class="headerlink" title="2.4.3 \Delta W_q和\Delta W_v的对比"></a>2.4.3 <script type="math/tex">\Delta W_q</script>和<script type="math/tex">\Delta W_v</script>的对比</h5><ul>
<li>作者采用了<script type="math/tex">r=64</script>，但是不用预训练权重，而是两次不同的随机初始化，来对模型进行训练，得到了两个不同的A矩阵<script type="math/tex">A_{r=64}, A'_{r=64}</script>，得到结果：</li>
</ul>
<p><img src="https://zlkqzimg-1310374208.cos.ap-chengdu.myqcloud.com/image-20230810161204970.png" srcset="/img/loading.gif" lazyload alt="image-20230810161204970" style="zoom:50%;" /></p>
<ul>
<li>分析结论：<strong>在不同的初始参数下，<script type="math/tex">\Delta W_q</script>共享重合的子空间（即相似度高的奇异矩阵子空间）的维度比<script type="math/tex">\Delta W_v</script>更高，说明<script type="math/tex">\Delta W_q</script>具有更高的intrinsic dimension，表明<script type="math/tex">\Delta W_q</script>学得的下游”task specific”信息更多</strong></li>
</ul>
<h5 id="2-4-4-W和-Delta-W的关系"><a href="#2-4-4-W和-Delta-W的关系" class="headerlink" title="2.4.4 W和\Delta W的关系"></a>2.4.4 <script type="math/tex">W</script>和<script type="math/tex">\Delta W</script>的关系</h5><ul>
<li>作者还对比了<script type="math/tex">W_q</script>以及其<script type="math/tex">A_{r=k}</script>的子空间相似度：</li>
</ul>
<p><img src="https://zlkqzimg-1310374208.cos.ap-chengdu.myqcloud.com/image-20230810162338348.png" srcset="/img/loading.gif" lazyload alt="image-20230810162338348" style="zoom:50%;" /></p>
<ul>
<li>分析结论：<strong>在<script type="math/tex">i = 400</script>周围，他们的子空间是几乎不重叠的，但是随着<script type="math/tex">i</script>的增加，子空间相似度居然又上来了。说明<script type="math/tex">\Delta W</script>所包含的奇异向量是<script type="math/tex">W</script>的奇异空间中很靠后的奇异向量。说明LoRA潜在地强调了一些重要特征，而这个特征是包含在预训练中，但是并没有在预训练中强调出来的task-specific特征</strong></li>
</ul>
<blockquote>
<p>This suggests that the low-rank adaptation matrix potentially amplifies the important features for specific downstream tasks that were learned but not emphasized in the general pre-training model  </p>
</blockquote>
<h1 id="3-QLoRA"><a href="#3-QLoRA" class="headerlink" title="3 QLoRA"></a>3 QLoRA</h1><h3 id="3-1-量化技术"><a href="#3-1-量化技术" class="headerlink" title="3.1 量化技术"></a>3.1 量化技术</h3><ul>
<li>最常见的量化方法是：</li>
</ul>
<script type="math/tex; mode=display">
\begin{gather}
Q = \frac{R}{S} + Z \\
R =(Q - Z) * S
\end{gather}</script><p>其中R表示量化前的值，Q表示量化后的值，<script type="math/tex">S = \frac{R_{\max} - R_{\min}}{Q_{\max} -Q_{min}}</script>表示缩放系数，<script type="math/tex">Z = Q_{\max} - R_{\max}/S</script>表示偏移量</p>
<ul>
<li>而在QLoRA中运用了更简化一点的形式：</li>
</ul>
<script type="math/tex; mode=display">
\begin{gather}
\mathbf{X}^{\mathrm{Int8}}=\operatorname{round}\left(\frac{127}{\operatorname{absmax}\left(\mathbf{X}^{\mathrm{FP} 32}\right)} \mathbf{X}^{\mathrm{FP} 32}\right)=\operatorname{round}\left(c^{\mathrm{FP} 32} \cdot \mathbf{X}^{\mathrm{FP} 32}\right) \\
\operatorname{dequant}\left(c^{\mathrm{FP} 32}, \mathbf{X}^{\mathrm{Int} 8}\right)=\frac{\mathbf{X}^{\mathrm{Int} 8}}{c^{\mathrm{FP} 32}}=\mathbf{X}^{\mathrm{FP} 32}
\end{gather}</script><ul>
<li>运用该方法主要是可以少存储一个偏移量</li>
<li>但是量化方法有一个通病：<strong>我们是希望量化后的每一个bit的利用率都尽可能高，即映射到每个bit的概率是差不多的，这样信息损失才更小。但是如果有很大的离群值，那么bit利用率会很低</strong></li>
<li>解决方法：<strong>采用分块量化，即将一个Tensor分为几个小块，分别量化和分别存储量化系数<script type="math/tex">c^{\mathrm{FP} 32}</script></strong></li>
</ul>
<h3 id="3-2-QLoRA实现"><a href="#3-2-QLoRA实现" class="headerlink" title="3.2 QLoRA实现"></a>3.2 QLoRA实现</h3><h5 id="3-2-1-4-bit-NormalFloat-Quantization"><a href="#3-2-1-4-bit-NormalFloat-Quantization" class="headerlink" title="3.2.1 4-bit NormalFloat Quantization"></a>3.2.1 4-bit NormalFloat Quantization</h5><ul>
<li>QLoRA是采用分位数量化，是将权重量化至4bit，并且量化的block_size为64，步骤如下：</li>
</ul>
<ol>
<li>采集<script type="math/tex">N(0,1)</script>的18分位点（有17个分位点），然后通过下式计算：</li>
</ol>
<script type="math/tex; mode=display">
q_{i}=\frac{1}{2}\left(Q_{X}\left(\frac{i}{2^{k}+1}\right)+Q_{X}\left(\frac{i+1}{2^{k}+1}\right)\right)</script><p>得到16个<script type="math/tex">q_i</script>，然后将这16个<script type="math/tex">q_i</script>除以<script type="math/tex">absmax(q_i)</script>，将其映射到<script type="math/tex">[-1,1]</script>，然后保存下来</p>
<ol>
<li>然后再将原权重除以量化常数<script type="math/tex">c^{\mathrm{FP} 32}</script>映射到<script type="math/tex">[-1,1]</script><strong>（注意这个<script type="math/tex">c^{\mathrm{FP} 32}</script>是要保存下来的，去量化的时候用）</strong>，和上一步保存的<script type="math/tex">q_i</script>对比，把原参数转为最近的<script type="math/tex">q_i</script>的index</li>
<li>去量化时再通过index查保存下来的<script type="math/tex">q_i</script>，再乘上之前除的即<script type="math/tex">c^{\mathrm{FP} 32}</script>可</li>
</ol>
<ul>
<li><p>上述方法存在问题：<strong>通过第一步得到的<script type="math/tex">q_i</script>中并没有0，所以在去量化后不会得到0，但是0在计算中是一个非常重要的值，所以去量化后必须得到准确的0</strong></p>
</li>
<li><p>解决方法：<strong>再加一个分位点，使用19分位点（有18个分位点），在17个得到<script type="math/tex">q_i</script>后（映射前的<script type="math/tex">q_i</script>），再将前8个映射到<script type="math/tex">[-1,0]</script>，后9个映射到<script type="math/tex">[0, 1]</script>，再将两部分合并（会丢弃一个重合的0），从而得到16个映射后的<script type="math/tex">q_i</script></strong></p>
</li>
<li><p>论文给出了通过这种方法所得到的<script type="math/tex">q_i</script>，直接保存下来使用即可，不需要现算：</p>
</li>
</ul>
<p><img src="https://zlkqzimg-1310374208.cos.ap-chengdu.myqcloud.com/image-20230829160539803.png" srcset="/img/loading.gif" lazyload alt="image-20230829160539803" style="zoom:40%;" /></p>
<h5 id="3-2-2-双量化"><a href="#3-2-2-双量化" class="headerlink" title="3.2.2 双量化"></a>3.2.2 双量化</h5><ul>
<li>上面说过，对于每个block（block_size=64），需要保存一个<script type="math/tex">c^{\mathrm{FP} 32}</script>，而这会造成<script type="math/tex">32/64=0.5</script>bits/parameter的内存增加</li>
<li><p>而双量化则是对这个<script type="math/tex">c^{\mathrm{FP} 32}</script>再做一次量化，将其映射到8bit，由于这个absmax很少会有离群值，所以block_size可以大些，第二次量化的block_size为256，这样就把内存增加降低至<script type="math/tex">8/64 + 32/(64 \times 256)=0.127</script>bits/parameter</p>
</li>
<li><p>并且由于<script type="math/tex">c^{\mathrm{FP} 32}</script>都为正，所以直接量化只会用到一半的bit，所以是先减去均值再量化。在去量化的时候，乘上<script type="math/tex">c^{\mathrm{FP} 32}</script>之后再算一波均值，然后再加上这个均值</p>
</li>
</ul>
<blockquote>
<ul>
<li>个人觉得这个双量化没啥必要哈，节省的内存也很有限说实话</li>
<li>另外QLoRA还用了Paged Optimizers优化了一些CPU、GPU内存调用的问题</li>
</ul>
</blockquote>
<h5 id="3-2-3-具体实现"><a href="#3-2-3-具体实现" class="headerlink" title="3.2.3 具体实现"></a>3.2.3 具体实现</h5><ul>
<li>首先，用上述方法将模型权重量化到4bit得到<script type="math/tex">W^{\mathrm{NF4}}</script>，再放入显存。训练是使用bf16精度，每次的计算步骤为：</li>
</ul>
<script type="math/tex; mode=display">
\begin{gather}
\mathbf{Y}^{\mathrm{BF} 16}=\mathbf{X}^{\mathrm{BF} 16} \text { doubleDequant }\left(c_{1}^{\mathrm{FP} 32}, c_{2}^{8\mathrm{bit}}, \mathbf{W}^{\mathrm{NF} 4}\right)+\mathbf{X}^{\mathrm{BF} 16} \mathbf{L}_{1}^{\mathrm{BF} 16} \mathbf{L}_{2}^{\mathrm{BF} 16} \\
\operatorname{doubleDequant}\left(c_{1}^{\mathrm{FP} 32}, c_{2}^{8 \text {bit }}, \mathbf{W}^{4 \text {bit }}\right)=\operatorname{dequant}\left(\operatorname{dequant}\left(c_{1}^{\mathrm{FP} 32}, c_{2}^{8\mathrm{bit}}\right), \mathbf{W}^{4 \mathrm{bit}}\right)=\mathbf{W}^{\mathrm{BF} 16}
\end{gather}</script><h3 id="3-3-对比实验"><a href="#3-3-对比实验" class="headerlink" title="3.3 对比实验"></a>3.3 对比实验</h3><h5 id="3-3-1-LoRA超参选择"><a href="#3-3-1-LoRA超参选择" class="headerlink" title="3.3.1 LoRA超参选择"></a>3.3.1 LoRA超参选择</h5><ul>
<li>LoRA论文中采用的只微调query和value矩阵，QLoRA还对比了其他超参，如全参数微调（Alpaca的训练方法）、只调FFN、对所有Attention Layer微调，实验结果：</li>
</ul>
<p><img src="https://zlkqzimg-1310374208.cos.ap-chengdu.myqcloud.com/image-20230829174543969.png" srcset="/img/loading.gif" lazyload alt="image-20230829174543969" style="zoom:33%;" /></p>
<ul>
<li><p>作者发现，<strong>原LoRA参数在QLoRA中并不能获得和全参数微调持平的结果，但是对所有Attention Layer微调可以，并且后面还有个实验说明了<script type="math/tex">r</script>的选择其实不是很重要</strong></p>
</li>
<li><p>另外，对比右边两列，发现Alpaca的超参选择的不好，所以自己又调了一版，结果更好</p>
</li>
</ul>
<h5 id="3-3-2-NF4-amp-amp-双量化"><a href="#3-3-2-NF4-amp-amp-双量化" class="headerlink" title="3.3.2 NF4 &amp;&amp; 双量化"></a>3.3.2 NF4 &amp;&amp; 双量化</h5><ul>
<li>作者对比了NF4和其他4-bit精度，并且探究了双量化对效果是否有影响，实验结果：</li>
</ul>
<p><img src="https://zlkqzimg-1310374208.cos.ap-chengdu.myqcloud.com/image-20230829175203934.png" srcset="/img/loading.gif" lazyload alt="image-20230829175203934" style="zoom:33%;" /></p>
<p><img src="https://zlkqzimg-1310374208.cos.ap-chengdu.myqcloud.com/image-20230829175357381.png" srcset="/img/loading.gif" lazyload alt="image-20230829175357381" style="zoom:40%;" /></p>
<h3 id="3-4-Chat-Bot-Evaluation"><a href="#3-4-Chat-Bot-Evaluation" class="headerlink" title="3.4 Chat-Bot Evaluation"></a>3.4 Chat-Bot Evaluation</h3><h5 id="3-4-1-训练配置"><a href="#3-4-1-训练配置" class="headerlink" title="3.4.1 训练配置"></a>3.4.1 训练配置</h5><ul>
<li>用<strong>OASST1、HH-RLHF、Alpaca 、self-instruct、unnatural-instructions、FLAN v2、Chip2、Longform</strong>等几个数据集微调LLaMA，<strong>并没有进行RLHF</strong></li>
<li>测评采用<strong>MMLU、对比ChatGPT、Elo Rating</strong>，MMLU采用5-shot测试，后两者是基于Vicuna prompts和OASST1的测试集（称为Vicuna benchmark）进行测评的，并且混合采用了人类和GPT-4进行测评</li>
<li>对比ChatGPT时，<strong>对于同一prompt，测评模型和ChatGPT生成的responses，分别打分（满分10分）。</strong>再计算该模型能达到ChatGPT性能的百分之几，100%为刚好打平</li>
<li><p>计算Elo Rating时，<strong>对于同一prompt，不同模型responses，进行三分类任务，选哪个更好或打平。</strong>再通过多次对比结果，计算Elo Rating</p>
</li>
<li><p>在采用GPT-4进行测评时，<strong>发现GPT-4会对在prompt中排靠前的answer有更多偏好，所以每次用GPT-4测评两次，依次将不同answer至于靠前位置，然后取平均分</strong></p>
</li>
<li><p>其中Guanaco是用QLoRA+OASST1数据集的变体微调的模型</p>
</li>
</ul>
<h5 id="3-4-2-实验结果"><a href="#3-4-2-实验结果" class="headerlink" title="3.4.2 实验结果"></a>3.4.2 实验结果</h5><ul>
<li><strong>不同数据集的微调结果：</strong></li>
</ul>
<p><img src="https://zlkqzimg-1310374208.cos.ap-chengdu.myqcloud.com/image-20230829191239069.png" srcset="/img/loading.gif" lazyload alt="image-20230829191239069" style="zoom:40%;" /></p>
<ul>
<li><strong>Competition with ChatGPT：</strong></li>
</ul>
<p><img src="https://zlkqzimg-1310374208.cos.ap-chengdu.myqcloud.com/image-20230829191321959.png" srcset="/img/loading.gif" lazyload alt="image-20230829191321735" style="zoom:35%;" /></p>
<ul>
<li><strong>Elo rating排行榜：</strong></li>
</ul>
<p><img src="https://zlkqzimg-1310374208.cos.ap-chengdu.myqcloud.com/image-20230829191406666.png" srcset="/img/loading.gif" lazyload alt="image-20230829191406666" style="zoom: 37%;" /></p>
<h5 id="3-4-3-结果分析"><a href="#3-4-3-结果分析" class="headerlink" title="3.4.3 结果分析"></a>3.4.3 结果分析</h5><ul>
<li>Guanaco能达到和ChatGPT差不多的水平，<strong>表明QLoRA在chat-bot表现上仍然很好</strong></li>
<li><strong>数据集和下游任务的匹配度才是最重要的</strong>，比如FLAN v2在MMLU上表现很好，但是在Vicuna benchmark上表现很差</li>
<li>并且还说明了MMLU并不能很全面地反映chat-bot的能力（个人理解：MMLU反映的是在多学科、多领域的知识能力以及知识覆盖面，而其他chat-bot能力反应的不是特别好）</li>
</ul>

            </div>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                
              </div>
              
                <p class="note note-warning">
                  
                    本博客所有文章除特别声明外，均采用 <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处！
                  
                </p>
              
              
                <div class="post-prevnext">
                  <article class="post-prev col-6">
                    
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2023/08/02/Megatron-LM/">
                        <span class="hidden-mobile">Megatron-LM</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
              <!-- Comments -->
              <article class="comments" id="comments" lazyload>
                
                  
                
                
  <div class="disqus" style="width:100%">
    <div id="disqus_thread"></div>
    
      <script type="text/javascript">
        var disqus_config = function() {
          this.page.url = 'https://zlkqz.github.io/2023/08/18/LoRA%20&amp;&amp;%20QLoRA/';
          this.page.identifier = '/2023/08/18/LoRA%20&amp;&amp;%20QLoRA/';
        };
        Fluid.utils.loadComments('#disqus_thread', function() {
          var d = document, s = d.createElement('script');
          s.src = '//' + 'fluid' + '.disqus.com/embed.js';
          s.setAttribute('data-timestamp', new Date());
          (d.head || d.body).appendChild(s);
        });
      </script>
    
    <noscript>Please enable JavaScript to view the comments</noscript>
  </div>


              </article>
            
          </article>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
    

    
  </main>

  <footer class="text-center mt-5 py-3">
  <div class="footer-content">
     <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
  </div>
  

  

  
</footer>


  <!-- SCRIPTS -->
  
  <script  src="https://cdn.jsdelivr.net/npm/nprogress@0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/nprogress@0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js" ></script>
<script  src="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>

<!-- Plugins -->


  <script  src="/js/local-search.js" ></script>



  
    <script  src="/js/img-lazyload.js" ></script>
  



  



  
    <script  src="https://cdn.jsdelivr.net/npm/tocbot@4/dist/tocbot.min.js" ></script>
  
  
    <script  src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3/dist/jquery.fancybox.min.js" ></script>
  
  
    <script  src="https://cdn.jsdelivr.net/npm/anchor-js@4/anchor.min.js" ></script>
  
  
    <script defer src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js" ></script>
  



  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>




  <script  src="https://cdn.jsdelivr.net/npm/typed.js@2/lib/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var title = document.getElementById('subtitle').title;
      
      typing(title)
      
    })(window, document);
  </script>





  

  
    <!-- MathJax -->
    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']]
        },
        loader: {
          load: ['ui/lazy']
        },
        options: {
          renderActions: {
            findScript: [10, doc => {
              document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
                const display = !!node.type.match(/; *mode=display/);
                const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
                const text = document.createTextNode('');
                node.parentNode.replaceChild(text, node);
                math.start = { node: text, delim: '', n: 0 };
                math.end = { node: text, delim: '', n: 0 };
                doc.math.push(math);
              });
            }, '', false],
            insertedScript: [200, () => {
              document.querySelectorAll('mjx-container').forEach(node => {
                let target = node.parentNode;
                if (target.nodeName.toLowerCase() === 'li') {
                  target.parentNode.classList.add('has-jax');
                }
              });
            }, '', false]
          }
        }
      };
    </script>

    <script async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js" ></script>

  











<!-- 主题的启动项 保持在最底部 -->
<script  src="/js/boot.js" ></script>


</body>
</html>
